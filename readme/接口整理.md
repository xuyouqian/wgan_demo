# wgan demo 用到的部分接口使用方法



### torchvision.io.read_image

接受图片的路径，返回图片的tensor

```python
import torchvision

img_demo_path = '../data/faces/1.jpg'
img = torchvision.io.read_image(img_demo_path)
print(img.shape)  # 3*96*96
```

### 读取到的图片的流水线处理

- transforms.ToPILImage()
  - 是转换数据格式，读取到的tensor把数据转换为tensfroms格式。只有转换为tensfroms格式才能进行后面的处理。

- transforms.Resize
  - 改变图片的形状
- transforms.ToTensor()
  - `ToTensor()`将`shape`为`(H, W, C)`的`nump.ndarray`或`img`转为`shape`为`(C, H, W)`的`tensor`，其将每一个数值归一化到`[0,1]`，其归一化方法比较简单，直接除以255即可。
- transforms.Normalize(）
  - 使用公式`"(x-mean)/std"`数据标准化  

```python
import torchvision
from torchvision import transforms
img_demo_path = '../data/faces/1.jpg'
img = torchvision.io.read_image(img_demo_path)

compose = [
    transforms.ToPILImage(),
    transforms.Resize((64, 64)),
    transforms.ToTensor(),
    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),
]
transform = transforms.Compose(compose)

img = transform(img)
print(img) # 可以看到已经标准化
print(img.shape) # torch.Size([3, 64, 64])
```



### 反卷积

```
torch.nn.ConvTranspose2d
```

图片的反卷积操作，可以扩大一张图片宽高

动画演示：

https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md

形状计算公式

- Input:$ (N, C_{in}, H_{in}, W_{in})or (C_{in}, H_{in}, W_{in})$
- Output: $(N, C_{out}, H_{out}, W_{out}) or (C_{out}, H_{out}, W_{out})$



$H_{out} = (H_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0] + \text{dilation}[0] \times (\text{kernel_size}[0] - 1) + \text{output_padding}[0] + 1$

$W_{out} = (W_{in} - 1) \times \text{stride}[1] - 2 \times \text{padding}[1] + \text{dilation}[1] \times (\text{kernel_size}[1] - 1) + \text{output_padding}[1] + 1$

代码

```python
from torch import nn

import torch

# 要扩展的图片
input_tensor = torch.randn([64 * 8, 4, 4])
in_dim = 64 * 8
out_dim = 64 * 4

# 这套参数可以吧图片的宽高扩展一倍
model = nn.ConvTranspose2d(in_dim, out_dim, kernel_size=5, stride=2,
                           padding=2, output_padding=1, bias=False)

output_tensor = model(input_tensor)
print(output_tensor.shape)  # [256,8,8]

```

### 模型参数初始化

```python
from torch import nn

import torch

def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        m.weight.data.normal_(0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        m.weight.data.normal_(1.0, 0.02)
        m.bias.data.fill_(0)


class Generator(nn.Module):
    """
    Input shape: (batch, in_dim)
    Output shape: (batch, 3, 64, 64)
    """

    def __init__(self, in_dim, feature_dim=64):
        super().__init__()

        # input: (batch, 100)
        self.l1 = nn.Sequential(
            nn.Linear(in_dim, feature_dim * 8 * 4 * 4, bias=False),
            nn.BatchNorm1d(feature_dim * 8 * 4 * 4),
            nn.ReLU()
        )
        self.l2 = nn.Sequential(
            self.dconv_bn_relu(feature_dim * 8, feature_dim * 4),  # (batch, feature_dim * 16, 8, 8)
            self.dconv_bn_relu(feature_dim * 4, feature_dim * 2),  # (batch, feature_dim * 16, 16, 16)
            self.dconv_bn_relu(feature_dim * 2, feature_dim),  # (batch, feature_dim * 16, 32, 32)
        )
        self.l3 = nn.Sequential(
            nn.ConvTranspose2d(feature_dim, 3, kernel_size=5, stride=2,
                               padding=2, output_padding=1, bias=False),
            nn.Tanh()
        )
        self.apply(weights_init)

    def dconv_bn_relu(self, in_dim, out_dim):
        return nn.Sequential(
            nn.ConvTranspose2d(in_dim, out_dim, kernel_size=5, stride=2,
                               padding=2, output_padding=1, bias=False),  # double height and width
            nn.BatchNorm2d(out_dim),
            nn.ReLU(True)
        )

    def forward(self, x):
        y = self.l1(x)
        y = y.view(y.size(0), -1, 4, 4)
        y = self.l2(y)
        y = self.l3(y)
        return y


g = Generator(64)

net_state_dict = g.state_dict()


for name,value in g.named_parameters():
    print(name)
    print(torch.mean(value).detach())
    print(torch.std(value).detach())
    print('---------------------------------')
'''

l1.0.weight
tensor(-7.5399e-06)
tensor(0.0721)
---------------------------------
l1.1.weight    有batch normal
tensor(0.9999)
tensor(0.0201)
---------------------------------
l1.1.bias
tensor(0.)
tensor(0.)
---------------------------------
l2.0.0.weight
tensor(2.4493e-06)
tensor(0.0200)
---------------------------------
l2.0.1.weight
tensor(1.0000)
tensor(0.0204)
---------------------------------
l2.0.1.bias
tensor(0.)
tensor(0.)
---------------------------------
l2.1.0.weight
tensor(3.6846e-06)
tensor(0.0200)
---------------------------------
l2.1.1.weight
tensor(0.9982)
tensor(0.0164)
---------------------------------
l2.1.1.bias
tensor(0.)
tensor(0.)
---------------------------------
l2.2.0.weight
tensor(2.6561e-05)
tensor(0.0200)
---------------------------------
l2.2.1.weight
tensor(0.9997)
tensor(0.0227)
---------------------------------
l2.2.1.bias
tensor(0.)
tensor(0.)
---------------------------------
l3.0.weight
tensor(-8.4211e-05)
tensor(0.0202)

'''
```



### glob.glob

`*` 可以匹配所有文件、目录、子目录和子目录里的文件

```python
import glob

root_path = '../data/faces'
# 匹配 root path 内部的所有文件
pathes = glob.glob(root_path + '/*')
print(pathes[:3]) # ['../data/faces/96.jpg', '../data/faces/153.jpg', '../data/faces/51.jpg']
```

